{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set default font to sans-serif\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "from utils.preprocessing import *\n",
    "from utils.visualization import *\n",
    "from utils.trainer import *\n",
    "from utils.config import *\n",
    "from utils.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of data by folds\n",
    "X_train_list = [pd.read_csv(path) for path in X_train_paths]\n",
    "y_train_list = [pd.read_csv(path) for path in y_train_paths]\n",
    "y_train_list = [y_train[TARGET].to_numpy() for y_train in y_train_list]\n",
    "\n",
    "X_val_list   = [pd.read_csv(path) for path in X_val_paths]\n",
    "y_val_list   = [pd.read_csv(path) for path in y_val_paths]\n",
    "y_val_list   = [y_val[TARGET].to_numpy() for y_val in y_val_list]\n",
    "\n",
    "y_val_full = []\n",
    "for y_val_fold in y_val_list:\n",
    "    y_val_full.extend(y_val_fold)\n",
    "assert len(y_val_full) == 273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['catboost', 'xgboost', 'lgbm', 'rf', 'svm', 'lr']\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for all models accross all folds\n",
    "pred_dict = {}\n",
    "pred_proba_dict = {}\n",
    "metric_dict = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    pred_list = []\n",
    "    pred_proba_list = []\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Load data for the current fold\n",
    "        X_train, y_train, X_val, y_val = load_data_fold(fold+1)\n",
    "\n",
    "        # Load trained model for the current fold\n",
    "        model = load_model_fold(fold+1, model_name=model_name)\n",
    "\n",
    "        # Get predictions for the current fold\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_proba = model.predict_proba(X_val)[:,-1]\n",
    "\n",
    "        pred_list.extend(y_pred)\n",
    "        pred_proba_list.extend(y_pred_proba)\n",
    "    \n",
    "    # Save predictions for this model\n",
    "    pred_dict[model_name] = pred_list\n",
    "    pred_proba_dict[model_name] = pred_proba_list\n",
    "\n",
    "    # Save metrics for this model\n",
    "    metric_dict[model_name] = calculate_metrics(y_val_full, pred_list, pred_proba_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_json('data/metrics.json', metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2. Evaluation Metrics for Six Machine Learning Models Across Five Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.8919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8548</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.8784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.8919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.8243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.8176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.8378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACC     AUC  F1 Score  Precision  Recall  Specificity\n",
       "catboost  0.8791  0.9312    0.8675     0.8710   0.864       0.8919\n",
       "xgboost   0.8645  0.9202    0.8514     0.8548   0.848       0.8784\n",
       "lgbm      0.8791  0.9150    0.8675     0.8710   0.864       0.8919\n",
       "rf        0.8388  0.9097    0.8295     0.8045   0.856       0.8243\n",
       "svm       0.8168  0.8985    0.8031     0.7907   0.816       0.8176\n",
       "lr        0.8132  0.8922    0.7935     0.8033   0.784       0.8378"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df = pd.DataFrame(metric_dict).T\n",
    "metric_df = round(metric_df, 4)\n",
    "metric_df.drop(columns='mse', inplace=True)\n",
    "metric_df.columns = ['ACC', 'AUC', 'F1 Score', 'Precision', 'Recall', 'Specificity']\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIStoCDMS-fgf1c-B4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
