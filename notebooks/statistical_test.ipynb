{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the sys.path to avoid 'ModuleNotFoundError'\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"font.family\"] = ['serif']\n",
    "\n",
    "from src.helpers import load_json, load_pickle\n",
    "from src.paths import paths\n",
    "from src.config import MODEL_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check if metrics have normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = load_json(paths.get('metric_fold_path'))\n",
    "metrics_to_analyze = [\n",
    "    'accuracy',\n",
    "    'roc_auc',\n",
    "    'f1_score',\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'specificity'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>normality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.946522</td>\n",
       "      <td>0.712336</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catboost</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.838784</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catboost</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.980866</td>\n",
       "      <td>0.939200</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catboost</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.940116</td>\n",
       "      <td>0.666758</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>catboost</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.802990</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>catboost</td>\n",
       "      <td>specificity</td>\n",
       "      <td>0.910757</td>\n",
       "      <td>0.472151</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.977634</td>\n",
       "      <td>0.921584</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.800256</td>\n",
       "      <td>0.081425</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.963147</td>\n",
       "      <td>0.829707</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.946566</td>\n",
       "      <td>0.712645</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.805882</td>\n",
       "      <td>0.090412</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>specificity</td>\n",
       "      <td>0.972904</td>\n",
       "      <td>0.893546</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.914506</td>\n",
       "      <td>0.495137</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.845051</td>\n",
       "      <td>0.179374</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.875131</td>\n",
       "      <td>0.287826</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.992925</td>\n",
       "      <td>0.988868</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.754427</td>\n",
       "      <td>0.032692</td>\n",
       "      <td>not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>specificity</td>\n",
       "      <td>0.921899</td>\n",
       "      <td>0.542261</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rf</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.967536</td>\n",
       "      <td>0.859217</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rf</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.966164</td>\n",
       "      <td>0.850109</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rf</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.985422</td>\n",
       "      <td>0.961354</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.875911</td>\n",
       "      <td>0.291190</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rf</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.952351</td>\n",
       "      <td>0.753973</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rf</td>\n",
       "      <td>specificity</td>\n",
       "      <td>0.643807</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>svm</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.928761</td>\n",
       "      <td>0.587945</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>svm</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.996844</td>\n",
       "      <td>0.997307</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>svm</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.951760</td>\n",
       "      <td>0.749757</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>svm</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.881378</td>\n",
       "      <td>0.315601</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>svm</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.952960</td>\n",
       "      <td>0.758312</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>svm</td>\n",
       "      <td>specificity</td>\n",
       "      <td>0.824689</td>\n",
       "      <td>0.126842</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lr</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.958475</td>\n",
       "      <td>0.797327</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.898395</td>\n",
       "      <td>0.401077</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lr</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.982897</td>\n",
       "      <td>0.949499</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lr</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.972488</td>\n",
       "      <td>0.890971</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lr</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.802990</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lr</td>\n",
       "      <td>specificity</td>\n",
       "      <td>0.936310</td>\n",
       "      <td>0.639985</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model       metric  statistic   p_value   normality\n",
       "0   catboost     accuracy   0.946522  0.712336      normal\n",
       "1   catboost      roc_auc   0.838784  0.161588      normal\n",
       "2   catboost     f1_score   0.980866  0.939200      normal\n",
       "3   catboost    precision   0.940116  0.666758      normal\n",
       "4   catboost       recall   0.802990  0.085693      normal\n",
       "5   catboost  specificity   0.910757  0.472151      normal\n",
       "6    xgboost     accuracy   0.977634  0.921584      normal\n",
       "7    xgboost      roc_auc   0.800256  0.081425      normal\n",
       "8    xgboost     f1_score   0.963147  0.829707      normal\n",
       "9    xgboost    precision   0.946566  0.712645      normal\n",
       "10   xgboost       recall   0.805882  0.090412      normal\n",
       "11   xgboost  specificity   0.972904  0.893546      normal\n",
       "12      lgbm     accuracy   0.914506  0.495137      normal\n",
       "13      lgbm      roc_auc   0.845051  0.179374      normal\n",
       "14      lgbm     f1_score   0.875131  0.287826      normal\n",
       "15      lgbm    precision   0.992925  0.988868      normal\n",
       "16      lgbm       recall   0.754427  0.032692  not normal\n",
       "17      lgbm  specificity   0.921899  0.542261      normal\n",
       "18        rf     accuracy   0.967536  0.859217      normal\n",
       "19        rf      roc_auc   0.966164  0.850109      normal\n",
       "20        rf     f1_score   0.985422  0.961354      normal\n",
       "21        rf    precision   0.875911  0.291190      normal\n",
       "22        rf       recall   0.952351  0.753973      normal\n",
       "23        rf  specificity   0.643807  0.002247  not normal\n",
       "24       svm     accuracy   0.928761  0.587945      normal\n",
       "25       svm      roc_auc   0.996844  0.997307      normal\n",
       "26       svm     f1_score   0.951760  0.749757      normal\n",
       "27       svm    precision   0.881378  0.315601      normal\n",
       "28       svm       recall   0.952960  0.758312      normal\n",
       "29       svm  specificity   0.824689  0.126842      normal\n",
       "30        lr     accuracy   0.958475  0.797327      normal\n",
       "31        lr      roc_auc   0.898395  0.401077      normal\n",
       "32        lr     f1_score   0.982897  0.949499      normal\n",
       "33        lr    precision   0.972488  0.890971      normal\n",
       "34        lr       recall   0.802990  0.085693      normal\n",
       "35        lr  specificity   0.936310  0.639985      normal"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_normality(metrics_dict, metrics_to_analyze):\n",
    "    results = []\n",
    "\n",
    "    for model, metrics_list in metrics_dict.items():\n",
    "        for metric in metrics_to_analyze:\n",
    "            values = [metrics[metric] for metrics in metrics_list]\n",
    "            stat, p_value = stats.shapiro(values)\n",
    "            result = {\n",
    "                'model': model,\n",
    "                'metric': metric,\n",
    "                'statistic': stat,\n",
    "                'p_value': p_value,\n",
    "                'normality': 'normal' if p_value > 0.05 else 'not normal'\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "normality_results_df = check_normality(metrics_dict, metrics_to_analyze)\n",
    "normality_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Comparing Model Performance for normally distributed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metric_scores(metrics_dict, metric_name):\n",
    "    metric_scores = {}\n",
    "    for model_name in MODEL_NAMES:\n",
    "        metric_scores[model_name] = [score[metric_name] for score in metrics_dict[model_name]]\n",
    "    return metric_scores\n",
    "\n",
    "def prepare_data_for_anova(metric_scores, metric_name):\n",
    "    data = pd.DataFrame(metric_scores)\n",
    "    data['Fold'] = list(range(1, 6))  # Adding fold information\n",
    "    data_long = pd.melt(data, id_vars=['Fold'], value_vars=data.columns[:-1], var_name='Model', value_name=metric_name)\n",
    "    return data_long\n",
    "\n",
    "def perform_repeated_measures_anova(data, metric_name):\n",
    "    rm_anova = AnovaRM(data, metric_name, 'Fold', within=['Model']).fit()\n",
    "    return rm_anova.summary()\n",
    "\n",
    "def perform_tukey_hsd(data, metric_name):\n",
    "    tukey = pairwise_tukeyhsd(endog=data[metric_name], groups=data['Model'], alpha=0.05)\n",
    "    return tukey.summary()\n",
    "\n",
    "def analyze_metric(metric_scores, metric_name):\n",
    "    data = prepare_data_for_anova(metric_scores, metric_name)\n",
    "\n",
    "    # Perform parametric tests\n",
    "    anova_summary = perform_repeated_measures_anova(data, metric_name)\n",
    "    print(anova_summary)\n",
    "\n",
    "    tukey_summary = perform_tukey_hsd(data, metric_name)\n",
    "    print(tukey_summary)\n",
    "\n",
    "    return anova_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing ACCURACY...\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Model  6.0849 5.0000 20.0000 0.0014\n",
      "===================================\n",
      "\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1   group2 meandiff p-adj   lower  upper  reject\n",
      "------------------------------------------------------\n",
      "catboost    lgbm   0.0001    1.0 -0.0877 0.0878  False\n",
      "catboost      lr  -0.0659 0.2238 -0.1537 0.0218  False\n",
      "catboost      rf  -0.0403 0.7157  -0.128 0.0475  False\n",
      "catboost     svm  -0.0624 0.2744 -0.1502 0.0253  False\n",
      "catboost xgboost  -0.0147 0.9949 -0.1025  0.073  False\n",
      "    lgbm      lr   -0.066 0.2229 -0.1537 0.0218  False\n",
      "    lgbm      rf  -0.0403 0.7143 -0.1281 0.0474  False\n",
      "    lgbm     svm  -0.0625 0.2734 -0.1502 0.0253  False\n",
      "    lgbm xgboost  -0.0148 0.9947 -0.1026 0.0729  False\n",
      "      lr      rf   0.0257 0.9417 -0.0621 0.1134  False\n",
      "      lr     svm   0.0035    1.0 -0.0843 0.0913  False\n",
      "      lr xgboost   0.0512 0.4824 -0.0366 0.1389  False\n",
      "      rf     svm  -0.0222 0.9682 -0.1099 0.0656  False\n",
      "      rf xgboost   0.0255 0.9429 -0.0622 0.1133  False\n",
      "     svm xgboost   0.0477 0.5572 -0.0401 0.1354  False\n",
      "------------------------------------------------------\n",
      "\n",
      "Analyzing ROC_AUC...\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Model  7.7014 5.0000 20.0000 0.0004\n",
      "===================================\n",
      "\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1   group2 meandiff p-adj   lower  upper  reject\n",
      "------------------------------------------------------\n",
      "catboost    lgbm  -0.0158 0.9649 -0.0771 0.0454  False\n",
      "catboost      lr  -0.0412   0.33 -0.1025   0.02  False\n",
      "catboost      rf  -0.0201 0.9087 -0.0814 0.0412  False\n",
      "catboost     svm  -0.0327 0.5772 -0.0939 0.0286  False\n",
      "catboost xgboost  -0.0118 0.9905 -0.0731 0.0495  False\n",
      "    lgbm      lr  -0.0254  0.792 -0.0867 0.0359  False\n",
      "    lgbm      rf  -0.0043 0.9999 -0.0655  0.057  False\n",
      "    lgbm     svm  -0.0168 0.9551 -0.0781 0.0445  False\n",
      "    lgbm xgboost   0.0041 0.9999 -0.0572 0.0654  False\n",
      "      lr      rf   0.0211 0.8897 -0.0401 0.0824  False\n",
      "      lr     svm   0.0086 0.9978 -0.0527 0.0699  False\n",
      "      lr xgboost   0.0295 0.6755 -0.0318 0.0908  False\n",
      "      rf     svm  -0.0126 0.9873 -0.0738 0.0487  False\n",
      "      rf xgboost   0.0083 0.9981  -0.053 0.0696  False\n",
      "     svm xgboost   0.0209 0.8946 -0.0404 0.0822  False\n",
      "------------------------------------------------------\n",
      "\n",
      "Analyzing F1_SCORE...\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Model  4.8673 5.0000 20.0000 0.0045\n",
      "===================================\n",
      "\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1   group2 meandiff p-adj   lower  upper  reject\n",
      "------------------------------------------------------\n",
      "catboost    lgbm   -0.001    1.0  -0.106 0.1039  False\n",
      "catboost      lr  -0.0739 0.2846 -0.1788 0.0311  False\n",
      "catboost      rf   -0.039 0.8556  -0.144 0.0659  False\n",
      "catboost     svm  -0.0649 0.4187 -0.1699   0.04  False\n",
      "catboost xgboost   -0.017 0.9957 -0.1219  0.088  False\n",
      "    lgbm      lr  -0.0728 0.2987 -0.1778 0.0321  False\n",
      "    lgbm      rf   -0.038 0.8688 -0.1429  0.067  False\n",
      "    lgbm     svm  -0.0639 0.4362 -0.1688 0.0411  False\n",
      "    lgbm xgboost  -0.0159 0.9968 -0.1209  0.089  False\n",
      "      lr      rf   0.0349 0.9042 -0.0701 0.1398  False\n",
      "      lr     svm   0.0089 0.9998  -0.096 0.1139  False\n",
      "      lr xgboost   0.0569 0.5591  -0.048 0.1619  False\n",
      "      rf     svm  -0.0259 0.9711 -0.1309  0.079  False\n",
      "      rf xgboost   0.0221 0.9857 -0.0829  0.127  False\n",
      "     svm xgboost    0.048  0.719  -0.057 0.1529  False\n",
      "------------------------------------------------------\n",
      "\n",
      "Analyzing PRECISION...\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Model  5.6513 5.0000 20.0000 0.0021\n",
      "===================================\n",
      "\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1   group2 meandiff p-adj   lower  upper  reject\n",
      "------------------------------------------------------\n",
      "catboost    lgbm  -0.0038    1.0 -0.0896  0.082  False\n",
      "catboost      lr  -0.0695 0.1618 -0.1553 0.0162  False\n",
      "catboost      rf  -0.0697 0.1598 -0.1555 0.0161  False\n",
      "catboost     svm  -0.0839 0.0577 -0.1697 0.0019  False\n",
      "catboost xgboost  -0.0181 0.9855 -0.1039 0.0677  False\n",
      "    lgbm      lr  -0.0657 0.2065 -0.1515   0.02  False\n",
      "    lgbm      rf  -0.0659 0.2041 -0.1517 0.0198  False\n",
      "    lgbm     svm  -0.0801 0.0768 -0.1659 0.0057  False\n",
      "    lgbm xgboost  -0.0143 0.9951 -0.1001 0.0715  False\n",
      "      lr      rf  -0.0002    1.0  -0.086 0.0856  False\n",
      "      lr     svm  -0.0144 0.9949 -0.1001 0.0714  False\n",
      "      lr xgboost   0.0514 0.4522 -0.0343 0.1372  False\n",
      "      rf     svm  -0.0142 0.9952    -0.1 0.0716  False\n",
      "      rf xgboost   0.0516 0.4484 -0.0341 0.1374  False\n",
      "     svm xgboost   0.0658 0.2054 -0.0199 0.1516  False\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics_to_analyze = ['accuracy', 'roc_auc', 'f1_score', 'precision']\n",
    "\n",
    "for metric_name in metrics_to_analyze:\n",
    "    print(f\"\\nAnalyzing {metric_name.upper()}...\\n\")\n",
    "    metric_scores = extract_metric_scores(metrics_dict, metric_name)\n",
    "    analyze_metric(metric_scores, metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Comparing Model Performance for not normally distributed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "def perform_friedman_test(metrics_dict, metric_name):\n",
    "    # Extract metric scores for all models\n",
    "    metric_scores = extract_metric_scores(metrics_dict, metric_name)\n",
    "    print(metric_scores)\n",
    "    \n",
    "    # Prepare the data in the format required for the Friedman test\n",
    "    # Each model's metric scores should be passed as a separate argument\n",
    "    scores = [metric_scores[model_name] for model_name in metric_scores]\n",
    "    print(scores)\n",
    "    \n",
    "    # Perform the Friedman test\n",
    "    stat, p_value = friedmanchisquare(*scores)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Friedman test result for {metric_name}:\")\n",
    "    print(f\"Test Statistic: {stat}\")\n",
    "    print(f\"P-Value: {p_value}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"The differences in {metric_name} between models are statistically significant.\")\n",
    "    else:\n",
    "        print(f\"No significant differences in {metric_name} between models were found.\")\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'catboost': [0.8545454545454545, 0.8909090909090909, 0.9090909090909091, 0.8703703703703703, 0.8703703703703703], 'xgboost': [0.7818181818181819, 0.9090909090909091, 0.9454545454545454, 0.8333333333333334, 0.8518518518518519], 'lgbm': [0.8, 0.9272727272727272, 0.9090909090909091, 0.8888888888888888, 0.8703703703703703], 'rf': [0.8, 0.8909090909090909, 0.8363636363636363, 0.8518518518518519, 0.8148148148148148], 'svm': [0.8, 0.8909090909090909, 0.8181818181818182, 0.7592592592592593, 0.8148148148148148], 'lr': [0.7636363636363637, 0.8727272727272727, 0.8181818181818182, 0.7962962962962963, 0.8148148148148148]}\n",
      "[[0.8545454545454545, 0.8909090909090909, 0.9090909090909091, 0.8703703703703703, 0.8703703703703703], [0.7818181818181819, 0.9090909090909091, 0.9454545454545454, 0.8333333333333334, 0.8518518518518519], [0.8, 0.9272727272727272, 0.9090909090909091, 0.8888888888888888, 0.8703703703703703], [0.8, 0.8909090909090909, 0.8363636363636363, 0.8518518518518519, 0.8148148148148148], [0.8, 0.8909090909090909, 0.8181818181818182, 0.7592592592592593, 0.8148148148148148], [0.7636363636363637, 0.8727272727272727, 0.8181818181818182, 0.7962962962962963, 0.8148148148148148]]\n",
      "Friedman test result for accuracy:\n",
      "Test Statistic: 16.187499999999996\n",
      "P-Value: 0.00632865051737763\n",
      "The differences in accuracy between models are statistically significant.\n",
      "\n",
      "{'catboost': [0.8986666666666666, 0.9520000000000001, 0.9466666666666665, 0.9241379310344827, 0.9475862068965518], 'xgboost': [0.8746666666666667, 0.9506666666666668, 0.9586666666666667, 0.8813793103448276, 0.9448275862068966], 'lgbm': [0.8786666666666667, 0.9586666666666667, 0.9373333333333334, 0.88, 0.9351724137931035], 'rf': [0.884, 0.9480000000000001, 0.92, 0.8979310344827587, 0.9186206896551724], 'svm': [0.8866666666666667, 0.9413333333333334, 0.904, 0.8593103448275863, 0.9144827586206896], 'lr': [0.864, 0.9306666666666666, 0.9026666666666666, 0.8606896551724138, 0.9048275862068966]}\n",
      "[[0.8986666666666666, 0.9520000000000001, 0.9466666666666665, 0.9241379310344827, 0.9475862068965518], [0.8746666666666667, 0.9506666666666668, 0.9586666666666667, 0.8813793103448276, 0.9448275862068966], [0.8786666666666667, 0.9586666666666667, 0.9373333333333334, 0.88, 0.9351724137931035], [0.884, 0.9480000000000001, 0.92, 0.8979310344827587, 0.9186206896551724], [0.8866666666666667, 0.9413333333333334, 0.904, 0.8593103448275863, 0.9144827586206896], [0.864, 0.9306666666666666, 0.9026666666666666, 0.8606896551724138, 0.9048275862068966]]\n",
      "Friedman test result for roc_auc:\n",
      "Test Statistic: 16.65714285714286\n",
      "P-Value: 0.005198098170259067\n",
      "The differences in roc_auc between models are statistically significant.\n",
      "\n",
      "{'catboost': [0.8333333333333334, 0.8846153846153846, 0.8979591836734694, 0.8679245283018868, 0.851063829787234], 'xgboost': [0.7391304347826086, 0.9019607843137255, 0.9387755102040817, 0.8301886792452831, 0.84], 'lgbm': [0.7659574468085106, 0.92, 0.9019607843137255, 0.8846153846153846, 0.8571428571428571], 'rf': [0.7755102040816326, 0.8888888888888888, 0.8235294117647058, 0.8518518518518519, 0.8], 'svm': [0.7755102040816326, 0.8846153846153846, 0.8076923076923077, 0.7346938775510204, 0.8076923076923077], 'lr': [0.7346938775510204, 0.8571428571428571, 0.8, 0.7659574468085106, 0.8076923076923077]}\n",
      "[[0.8333333333333334, 0.8846153846153846, 0.8979591836734694, 0.8679245283018868, 0.851063829787234], [0.7391304347826086, 0.9019607843137255, 0.9387755102040817, 0.8301886792452831, 0.84], [0.7659574468085106, 0.92, 0.9019607843137255, 0.8846153846153846, 0.8571428571428571], [0.7755102040816326, 0.8888888888888888, 0.8235294117647058, 0.8518518518518519, 0.8], [0.7755102040816326, 0.8846153846153846, 0.8076923076923077, 0.7346938775510204, 0.8076923076923077], [0.7346938775510204, 0.8571428571428571, 0.8, 0.7659574468085106, 0.8076923076923077]]\n",
      "Friedman test result for f1_score:\n",
      "Test Statistic: 13.343023255813954\n",
      "P-Value: 0.02036779163580134\n",
      "The differences in f1_score between models are statistically significant.\n",
      "\n",
      "{'catboost': [0.8695652173913043, 0.8518518518518519, 0.9166666666666666, 0.8214285714285714, 0.9090909090909091], 'xgboost': [0.8095238095238095, 0.8846153846153846, 0.9583333333333334, 0.7857142857142857, 0.84], 'lgbm': [0.8181818181818182, 0.92, 0.8846153846153846, 0.8518518518518519, 0.875], 'rf': [0.7916666666666666, 0.8275862068965517, 0.8076923076923077, 0.7931034482758621, 0.8], 'svm': [0.7916666666666666, 0.8518518518518519, 0.7777777777777778, 0.75, 0.7777777777777778], 'lr': [0.75, 0.875, 0.8, 0.8181818181818182, 0.7777777777777778]}\n",
      "[[0.8695652173913043, 0.8518518518518519, 0.9166666666666666, 0.8214285714285714, 0.9090909090909091], [0.8095238095238095, 0.8846153846153846, 0.9583333333333334, 0.7857142857142857, 0.84], [0.8181818181818182, 0.92, 0.8846153846153846, 0.8518518518518519, 0.875], [0.7916666666666666, 0.8275862068965517, 0.8076923076923077, 0.7931034482758621, 0.8], [0.7916666666666666, 0.8518518518518519, 0.7777777777777778, 0.75, 0.7777777777777778], [0.75, 0.875, 0.8, 0.8181818181818182, 0.7777777777777778]]\n",
      "Friedman test result for precision:\n",
      "Test Statistic: 15.377906976744185\n",
      "P-Value: 0.008863946356156603\n",
      "The differences in precision between models are statistically significant.\n",
      "\n",
      "{'catboost': [0.8, 0.92, 0.88, 0.92, 0.8], 'xgboost': [0.68, 0.92, 0.92, 0.88, 0.84], 'lgbm': [0.72, 0.92, 0.92, 0.92, 0.84], 'rf': [0.76, 0.96, 0.84, 0.92, 0.8], 'svm': [0.76, 0.92, 0.84, 0.72, 0.84], 'lr': [0.72, 0.84, 0.8, 0.72, 0.84]}\n",
      "[[0.8, 0.92, 0.88, 0.92, 0.8], [0.68, 0.92, 0.92, 0.88, 0.84], [0.72, 0.92, 0.92, 0.92, 0.84], [0.76, 0.96, 0.84, 0.92, 0.8], [0.76, 0.92, 0.84, 0.72, 0.84], [0.72, 0.84, 0.8, 0.72, 0.84]]\n",
      "Friedman test result for recall:\n",
      "Test Statistic: 4.999999999999996\n",
      "P-Value: 0.41588018699550844\n",
      "No significant differences in recall between models were found.\n",
      "\n",
      "{'catboost': [0.9, 0.8666666666666667, 0.9333333333333333, 0.8275862068965517, 0.9310344827586207], 'xgboost': [0.8666666666666667, 0.9, 0.9666666666666667, 0.7931034482758621, 0.8620689655172413], 'lgbm': [0.8666666666666667, 0.9333333333333333, 0.9, 0.8620689655172413, 0.896551724137931], 'rf': [0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.7931034482758621, 0.8275862068965517], 'svm': [0.8333333333333334, 0.8666666666666667, 0.8, 0.7931034482758621, 0.7931034482758621], 'lr': [0.8, 0.9, 0.8333333333333334, 0.8620689655172413, 0.7931034482758621]}\n",
      "[[0.9, 0.8666666666666667, 0.9333333333333333, 0.8275862068965517, 0.9310344827586207], [0.8666666666666667, 0.9, 0.9666666666666667, 0.7931034482758621, 0.8620689655172413], [0.8666666666666667, 0.9333333333333333, 0.9, 0.8620689655172413, 0.896551724137931], [0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.7931034482758621, 0.8275862068965517], [0.8333333333333334, 0.8666666666666667, 0.8, 0.7931034482758621, 0.7931034482758621], [0.8, 0.9, 0.8333333333333334, 0.8620689655172413, 0.7931034482758621]]\n",
      "Friedman test result for specificity:\n",
      "Test Statistic: 13.23170731707316\n",
      "P-Value: 0.021301521953202084\n",
      "The differences in specificity between models are statistically significant.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_to_analyze = ['accuracy', 'roc_auc', 'f1_score', 'precision', 'recall', 'specificity']\n",
    "\n",
    "for metric_name in metrics_to_analyze:\n",
    "    perform_friedman_test(metrics_dict, metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "def identify_different_models(metrics_dict, metric_name):\n",
    "    # Extract metric scores for all models\n",
    "    metric_scores = extract_metric_scores(metrics_dict, metric_name)\n",
    "    \n",
    "    # Prepare the data in the format required for the Friedman test\n",
    "    scores = np.array([metric_scores[model_name] for model_name in metric_scores])\n",
    "\n",
    "    # Perform the Friedman test\n",
    "    stat, p_value = friedmanchisquare(*scores)\n",
    "    \n",
    "    print(f\"Friedman test result for {metric_name}:\")\n",
    "    print(f\"Test Statistic: {stat}\")\n",
    "    print(f\"P-Value: {p_value}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"The differences in {metric_name} between models are statistically significant.\")\n",
    "        \n",
    "        # Perform the Nemenyi post-hoc test\n",
    "        nemenyi_results = posthoc_nemenyi_friedman(scores.T)\n",
    "        \n",
    "        print(\"\\nNemenyi post-hoc test results:\")\n",
    "        print(nemenyi_results)\n",
    "        \n",
    "        # Highlight significant differences\n",
    "        significant_pairs = np.where(nemenyi_results < 0.05)\n",
    "        for i in range(len(significant_pairs[0])):\n",
    "            model1 = list(metric_scores.keys())[significant_pairs[0][i]]\n",
    "            model2 = list(metric_scores.keys())[significant_pairs[1][i]]\n",
    "            print(f\"Significant difference between {model1} and {model2}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"No significant differences in {metric_name} between models were found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test result for accuracy:\n",
      "Test Statistic: 16.187499999999996\n",
      "P-Value: 0.00632865051737763\n",
      "The differences in accuracy between models are statistically significant.\n",
      "\n",
      "Nemenyi post-hoc test results:\n",
      "          0         1         2         3         4         5\n",
      "0  1.000000  0.900000  0.900000  0.727962  0.280498  0.059278\n",
      "1  0.900000  1.000000  0.900000  0.900000  0.679147  0.280498\n",
      "2  0.900000  0.900000  1.000000  0.532706  0.138788  0.021823\n",
      "3  0.727962  0.900000  0.532706  1.000000  0.900000  0.679147\n",
      "4  0.280498  0.679147  0.138788  0.900000  1.000000  0.900000\n",
      "5  0.059278  0.280498  0.021823  0.679147  0.900000  1.000000\n",
      "Significant difference between lgbm and lr\n",
      "Significant difference between lr and lgbm\n",
      "Friedman test result for roc_auc:\n",
      "Test Statistic: 16.65714285714286\n",
      "P-Value: 0.005198098170259067\n",
      "The differences in roc_auc between models are statistically significant.\n",
      "\n",
      "Nemenyi post-hoc test results:\n",
      "          0         1         2         3         4         5\n",
      "0  1.000000  0.825589  0.727962  0.532706  0.074521  0.002751\n",
      "1  0.825589  1.000000  0.900000  0.900000  0.630333  0.114066\n",
      "2  0.727962  0.900000  1.000000  0.900000  0.727962  0.168277\n",
      "3  0.532706  0.900000  0.900000  1.000000  0.900000  0.325848\n",
      "4  0.074521  0.630333  0.727962  0.900000  1.000000  0.900000\n",
      "5  0.002751  0.114066  0.168277  0.325848  0.900000  1.000000\n",
      "Significant difference between catboost and lr\n",
      "Significant difference between lr and catboost\n",
      "Friedman test result for f1_score:\n",
      "Test Statistic: 13.343023255813954\n",
      "P-Value: 0.02036779163580134\n",
      "The differences in f1_score between models are statistically significant.\n",
      "\n",
      "Nemenyi post-hoc test results:\n",
      "          0         1         2         3         4         5\n",
      "0  1.000000  0.900000  0.900000  0.900000  0.532706  0.114066\n",
      "1  0.900000  1.000000  0.900000  0.900000  0.776774  0.280498\n",
      "2  0.900000  0.900000  1.000000  0.581521  0.201286  0.021823\n",
      "3  0.900000  0.900000  0.581521  1.000000  0.900000  0.630333\n",
      "4  0.532706  0.776774  0.201286  0.900000  1.000000  0.900000\n",
      "5  0.114066  0.280498  0.021823  0.630333  0.900000  1.000000\n",
      "Significant difference between lgbm and lr\n",
      "Significant difference between lr and lgbm\n",
      "Friedman test result for precision:\n",
      "Test Statistic: 15.377906976744185\n",
      "P-Value: 0.008863946356156603\n",
      "The differences in precision between models are statistically significant.\n",
      "\n",
      "Nemenyi post-hoc test results:\n",
      "          0         1         2         3         4         5\n",
      "0  1.000000  0.900000  0.900000  0.325848  0.074521  0.325848\n",
      "1  0.900000  1.000000  0.900000  0.679147  0.280498  0.679147\n",
      "2  0.900000  0.900000  1.000000  0.201286  0.036601  0.201286\n",
      "3  0.325848  0.679147  0.201286  1.000000  0.900000  0.900000\n",
      "4  0.074521  0.280498  0.036601  0.900000  1.000000  0.900000\n",
      "5  0.325848  0.679147  0.201286  0.900000  0.900000  1.000000\n",
      "Significant difference between lgbm and svm\n",
      "Significant difference between svm and lgbm\n",
      "Friedman test result for recall:\n",
      "Test Statistic: 4.999999999999996\n",
      "P-Value: 0.41588018699550844\n",
      "No significant differences in recall between models were found.\n",
      "Friedman test result for specificity:\n",
      "Test Statistic: 13.23170731707316\n",
      "P-Value: 0.021301521953202084\n",
      "The differences in specificity between models are statistically significant.\n",
      "\n",
      "Nemenyi post-hoc test results:\n",
      "          0         1         2         3         4         5\n",
      "0  1.000000  0.900000  0.900000  0.280498  0.168277  0.679147\n",
      "1  0.900000  1.000000  0.900000  0.532706  0.376391  0.900000\n",
      "2  0.900000  0.900000  1.000000  0.168277  0.092236  0.532706\n",
      "3  0.280498  0.532706  0.168277  1.000000  0.900000  0.900000\n",
      "4  0.168277  0.376391  0.092236  0.900000  1.000000  0.900000\n",
      "5  0.679147  0.900000  0.532706  0.900000  0.900000  1.000000\n"
     ]
    }
   ],
   "source": [
    "metrics_to_analyze = ['accuracy', 'roc_auc', 'f1_score', 'precision', 'recall', 'specificity']\n",
    "\n",
    "for metric_name in metrics_to_analyze:\n",
    "    identify_different_models(metrics_dict, metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Comparing the Impact of Features Using SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = load_pickle(paths.get('shap_values_path'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values['catboost'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_values['catboost'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIStoCDMS-fgf1c-B4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
